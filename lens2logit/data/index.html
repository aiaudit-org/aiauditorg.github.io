<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>aiaudit  .org | From Lens to Logit - Data</title>
<meta name="description" content="">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/lens2logit/data/">

<!-- Theming-->




    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


    <script src="/assets/js/distillpub/template.v2.js"></script>
    <script src="/assets/js/distillpub/transforms.v2.js"></script>
    
    <style type="text/css">
      .fake-img {
  background: #bbb;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
  margin-bottom: 12px;
} .fake-img p {
  font-family: monospace;
  color: white;
  text-align: left;
  margin: 12px 0;
  text-align: center;
  font-size: 16px;
}

    </style>
    
  </head>

  <d-front-matter>
    <script async type="text/json">{
      "title": "From Lens to Logit - Data",
      "description": "",
      "published": "2021-08-27",
      "authors": [
        
        {
          "author": "Luis Oala",
          "authorURL": "https://luisoala.net/",
          "affiliations": [
            {
              "name": "Fraunhofer HHI",
              "url": ""
            }
          ]
        },
        
        {
          "author": "Marco Aversa",
          "authorURL": "https://aiaudit.org/lens2logit/",
          "affiliations": [
            {
              "name": "University of Glasgow",
              "url": ""
            }
          ]
        },
        
        {
          "author": "Kurt Willis",
          "authorURL": "https://aiaudit.org/lens2logit/",
          "affiliations": [
            {
              "name": "Fraunhofer HHI",
              "url": ""
            }
          ]
        },
        
        {
          "author": "Gabriel Nobis",
          "authorURL": "https://aiaudit.org/lens2logit/",
          "affiliations": [
            {
              "name": "Fraunhofer HHI",
              "url": ""
            }
          ]
        },
        
        {
          "author": "Yoan Neuenschwander",
          "authorURL": "https://aiaudit.org/lens2logit/",
          "affiliations": [
            {
              "name": "HEPIA/HES-SO",
              "url": ""
            }
          ]
        },
        
        {
          "author": "Michèle Buck",
          "authorURL": "https://aiaudit.org/lens2logit/",
          "affiliations": [
            {
              "name": "Klinikum rechts der Isar",
              "url": ""
            }
          ]
        },
        
        {
          "author": "Christian Matek",
          "authorURL": "https://aiaudit.org/lens2logit/",
          "affiliations": [
            {
              "name": "Helmholtz Zentrum Munich",
              "url": ""
            }
          ]
        },
        
        {
          "author": "Jérôme Extermann",
          "authorURL": "https://aiaudit.org/lens2logit/",
          "affiliations": [
            {
              "name": "HEPIA/HES-SO",
              "url": ""
            }
          ]
        },
        
        {
          "author": "Enrico Pomarico",
          "authorURL": "https://aiaudit.org/lens2logit/",
          "affiliations": [
            {
              "name": "HEPIA/HES-SO",
              "url": ""
            }
          ]
        },
        
        {
          "author": "Roderick Murray-Smith",
          "authorURL": "https://aiaudit.org/lens2logit/",
          "affiliations": [
            {
              "name": "University of Glasgow",
              "url": ""
            }
          ]
        },
        
        {
          "author": "Christoph Clausen",
          "authorURL": "https://aiaudit.org/lens2logit/",
          "affiliations": [
            {
              "name": "Dotphoton AG",
              "url": ""
            }
          ]
        },
        
        {
          "author": "Bruno Sanguinetti",
          "authorURL": "https://aiaudit.org/lens2logit/",
          "affiliations": [
            {
              "name": "Dotphoton AG",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>

  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="https://aiaudit.org/">
       <span class="font-weight-bold">aiaudit</span>.org
      </a>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              About
              
            </a>
          </li>
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/contributors/">
                Contributors
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/join/">
                Join
                
              </a>
          </li>
          
          
          

          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="post distill">

      <d-title>
        <h1>From Lens to Logit - Data</h1>
        <p></p>
      </d-title>

      <d-byline></d-byline>

      <d-article>
        <p><strong>Data</strong> <a href="https://doi.org/10.5281/zenodo.5235536"><img src="https://zenodo.org/badge/DOI/10.5281/zenodo.5235536.svg" alt="DOI" /></a></p>

<p><a href="https://github.com/aiaudit-org/website/blob/master/assets/pdf/lens2logit-datasheets.pdf"><strong>Datasheets for both datasets</strong></a>
<!---<d-cite key="gregor2015draw"></d-cite>---></p>

<p><em>This page contains information on the data used in the manuscript <a href="https://openreview.net/forum?id=DRAywM1BhU">“From Lens to Logit: Addressing Camera Hardware-Drift Using Raw Sensor Data”</a>, submitted to the NeurIPS 2021 Datasets and Benchmarks Track. You can find more information on the <a href="https://aiaudit.org/lens2logit/">project page</a>.</em></p>

<p>Within the Lens2Logit framework, we make available two datasets: <strong>Raw-Microscopy</strong> and <strong>Raw-Drone</strong></p>

<h2 id="raw-microscopy">Raw-Microscopy</h2>
<p>The dataset Raw-Microscopy contains:</p>
<ul>
  <li><strong>940 raw bright-field microscopy images</strong> of human blood smear slides for leukocyte classification with corresponding labels,</li>
  <li><strong>5,640 variations</strong> measured at <strong>six</strong> additional <strong>different intensities</strong> and</li>
  <li><strong>11,280 images of the raw sensor data processed through twelve different pipelines</strong>.</li>
</ul>

<table>
  <thead>
    <tr>
      <th>Property</th>
      <th style="text-align: right">Value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Types of instances</td>
      <td style="text-align: right">image and label</td>
    </tr>
    <tr>
      <td>Objects on images</td>
      <td style="text-align: right">white blood cells</td>
    </tr>
    <tr>
      <td>Type of classes</td>
      <td style="text-align: right">morphological classes</td>
    </tr>
    <tr>
      <td>Number of instances</td>
      <td style="text-align: right">940</td>
    </tr>
    <tr>
      <td>Number of classes</td>
      <td style="text-align: right">9</td>
    </tr>
    <tr>
      <td>Image size</td>
      <td style="text-align: right">256 by 256 pixels</td>
    </tr>
    <tr>
      <td>Image format</td>
      <td style="text-align: right">tiff</td>
    </tr>
  </tbody>
</table>

<table>
  <thead>
    <tr>
      <th>Class</th>
      <th style="text-align: right">Proportion</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Basophil (BAS)</td>
      <td style="text-align: right">1.91 %</td>
    </tr>
    <tr>
      <td>Eosinophil (EOS)</td>
      <td style="text-align: right">5.74 %</td>
    </tr>
    <tr>
      <td>Smudge cell / debris (KSC)</td>
      <td style="text-align: right">17.34 %</td>
    </tr>
    <tr>
      <td>atypical Lymphocyte (LYA)</td>
      <td style="text-align: right">3.19 %</td>
    </tr>
    <tr>
      <td>typical Lymphocyte (LYT)</td>
      <td style="text-align: right">24.47 %</td>
    </tr>
    <tr>
      <td>Monocyte (MON)</td>
      <td style="text-align: right">20.32 %</td>
    </tr>
    <tr>
      <td>Neutrophil (band) (NGB)</td>
      <td style="text-align: right">0.85 %</td>
    </tr>
    <tr>
      <td>Neutrophil (segmented) (NGS)</td>
      <td style="text-align: right">22.98 %</td>
    </tr>
    <tr>
      <td>Image that could not be assigned a class (UNC)</td>
      <td style="text-align: right">3.19 %</td>
    </tr>
  </tbody>
</table>

<h3 id="data-acquisition">Data acquisition</h3>
<p>Assessment of blood smears under a light microscope is a key diagnostic technique <d-cite key="Bain2005"></d-cite>. The creation of image datasets and machnine learning models on them has received wide interest in recent years <d-cite key="Scotti2011"></d-cite><d-cite key="Matek2019"></d-cite><d-cite key="Ayyappan2020"></d-cite>. Here, we use a bright-field microscope to image blood smear cytopathology samples. The light source is a halogen lamp equipped with a 0.55 NA condenser, and a pre-centred field diaphragm unit. We use filters at 450 nm, 525 nm and 620 nm to acquire the blue, green and red channels respectively. The condenser is followed by a 40 \(\times\) objective with 0.95 NA (Olympus UPLXAPO40X). Slides can be moved via a piezo with 1 nm spatial resolution, in the three directions. We focus by maximizing the variance of the pixel values. Images are acquired is 16 bit, with a 2560 \(\times\) 2160 pixels CMOS sensor (PCO edge 5.5). We measured the PSF to be 450 nm with 100 nm nanospheres. Mechanical drift was measured at 0.4 pixels per hour. Imaging was performed on de-identified human blood smear slides (Ma190c Lieder, J. Lieder GmbH &amp; Co. KG, Ludwigsburg/Germany). All slides were taken from healthy humans without known hematologic pathology. Imaging regions were selected to contain single leukoytes in order to allow unique labelling of image patches, and regions were cropped to 256 \(\times\) 256 pixels. All images were annotated by a trained hematological cytologist using the standard scheme of normal leukocytes comprising band and segmented neutrophils, typical and atypical lymphocytes, monocytes, eosinophils and basophils <d-cite key="longanbach2016rodak"></d-cite>. To soften class imbalance, candidates for rare normal leukocyte types were preferentially imaged, and enrich rare classes. Additionally, two classes for debris and smudge cells, as well as cells of unclear morphology were included. Labelling took place for all imaged cells from a particular smear at a time, with single-cell patches shown in random order. RI are generated using JetRaw Data Suite features. Blue, red and green channels are metrologically rescaled independently in intensity to simulate a standard RGB camera condition. From each channel, some pixels are discarded complementary on each channel in order to obtain a Bayer filter pattern.</p>
<h3 id="labels">Labels</h3>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/lens2logit/Microscopy_classes.png" data-zoomable="" />
    </div>
</div>
<div class="caption">
     Samples from each class in the Raw-Microscopy dataset.
</div>

<h3 id="intensity-levels">Intensity levels</h3>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/lens2logit/DifferentIntensities.png" data-zoomable="" />
    </div>
</div>
<div class="caption">
     Raw data at different intensity levels.
</div>

<h3 id="static-processed-variations">Static processed variations</h3>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/lens2logit/ABpipelines_Microscopy.png" data-zoomable="" />
    </div>
</div>
<div class="caption">
    Static processing variations on the Raw Microscopy dataset.
</div>

<h2 id="raw-drone">Raw-Drone</h2>
<p>The dataset Raw-Drone contains:</p>
<ul>
  <li><strong>548 raw drone camera images</strong> for car segmentation with corresponding binary segmentation mask. The images and the masks are cropped from 12 raw drone camera images and 12 masks of size 3648 by 5472,</li>
  <li><strong>3,288 variations</strong> measured at <strong>six</strong> additional <strong>different intensities</strong> and</li>
  <li><strong>6,576 images of the raw sensor data processed through twelve different pipelines</strong>.</li>
</ul>

<table>
  <thead>
    <tr>
      <th>Property</th>
      <th style="text-align: right">Value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Types of instances</td>
      <td style="text-align: right">image and mask</td>
    </tr>
    <tr>
      <td>Objects on images</td>
      <td style="text-align: right">landscape shots from above</td>
    </tr>
    <tr>
      <td>Number of instances</td>
      <td style="text-align: right">548</td>
    </tr>
    <tr>
      <td>Number of original images</td>
      <td style="text-align: right">12</td>
    </tr>
    <tr>
      <td>Image size</td>
      <td style="text-align: right">256 by 256 pixels</td>
    </tr>
    <tr>
      <td>Mask size</td>
      <td style="text-align: right">256 by 256 pixels</td>
    </tr>
    <tr>
      <td>Original image size</td>
      <td style="text-align: right">3648 by 5472 pixels</td>
    </tr>
    <tr>
      <td>Image format</td>
      <td style="text-align: right">tif</td>
    </tr>
    <tr>
      <td>Mask format</td>
      <td style="text-align: right">png</td>
    </tr>
    <tr>
      <td>Original image format</td>
      <td style="text-align: right">DNG</td>
    </tr>
  </tbody>
</table>

<h3 id="data-acquisition-1">Data acquisition</h3>
<p>We used a DJI Mavic 2 Pro Drone, equipped with a Hasselblad L1D-20c camera (Sony IMX183 sensor) having 2.4 $\micro$m pixels in Bayer filter array. The objective has a focal length of 10.3 mm. We set the f-number \(N=8\), to emulate the PSF circle diameter relative to the pixel pitch and ground sampling distance (GSD) as would be found on images from high-resolution satellites. The point-spread function (PSF) was measured to have a circle diameter of 12.5$\micro$m. This corresponds to a diffraction-limited system, within the uncertainty dominated by the wavelength spread of the image. Images were taken at 200 ISO, a gain of 0.528 DN/$e^-$. The 12-bit pixel values are however left-justified to 16-bits, so that the gain on the 16-bit numbers is 8.448 DN/$e^-$. The images were taken at a height of 250 m, so that the GSD is 6 cm. All images were tiled in 256  \(\times\) 256 patches. Segmentation color masks were created to identify cars for each patch. From this mask, classification labels were generated to detect if there is a car in the image. The dataset is constituted by 548 images for the segmentation task, and 930 for classification. The dataset is augmented through JetRaw Data Suite, with 7 different intensity scales.</p>
<h3 id="labels-1">Labels</h3>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/lens2logit/Drone_masks.png" data-zoomable="" />
    </div>
</div>
<div class="caption">
     Samples of masks in the Raw-Drone dataset.
</div>

<!---### Intensity levels--->
<h3 id="static-processed-variations-1">Static processed variations</h3>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/lens2logit/ABpipelines_Drone.png" data-zoomable="" />
    </div>
</div>
<div class="caption">
     Static processing variations on the Raw Drone dataset.
</div>

<h2 id="access">Access</h2>
<p>If you use our code you can use the convenient cloud storage integration. Data will be loaded automatically.
We also maintain a copy of the entire dataset with a persistent and permanent identifier at Zenodo which you can find under identifier <a href="https://doi.org/10.5281/zenodo.5235536">10.5281/zenodo.5235536</a>.</p>
<h2 id="license">License</h2>
<p>The data is published under a <a href="https://creativecommons.org/licenses/by/4.0/">Attribution 4.0 International (CC BY 4.0)</a> which allows liberal copying, redistribution, remixing and transformation.
The authors bear all responsibility for the published data.</p>


      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

    </div>

    <!-- Footer -->

    
<footer class="sticky-bottom mt-5">
  <div class="container">
    <!-- &copy; Copyright 2021 aiaudit  .org. -->
    Thanks to <a href="https://github.com/alshedivat/al-folio">Maruan</a> for the neat theme base

    
  </div>
</footer>



  </body>

  <d-bibliography src="/assets/bibliography/lens2logit.bib">
  </d-bibliography>

</html>
